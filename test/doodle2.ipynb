{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DBHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DBHandler import Handler\n",
    "from redis import Redis\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras import models\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import keras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Modeling():\n",
    "\n",
    "    def __init__(self, key):\n",
    "        redis = Redis()\n",
    "        handler = Handler(redis)\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.data = handler.load_all(key)\n",
    "        self.data = pd.DataFrame(self.data)\n",
    "        self.data[['close']] = self.scaler.fit_transform(self.data[['close']])\n",
    "        self.predictAhead = 5\n",
    "        self.time_steps = 15\n",
    "\n",
    "    def graph(self):\n",
    "        priceList = self.data['close'].values\n",
    "        priceList = np.append(priceList, self.pred)\n",
    "        priceList = np.reshape(priceList, (-1, 1))\n",
    "        priceList = self.scaler.inverse_transform(priceList)\n",
    "        minList = self.data['relative_minute'].values\n",
    "        for i in range(self.predictAhead):\n",
    "            minList = np.append(minList, (minList[-1] + 1))\n",
    "        # priceList = np.reshape(priceList, (-1,1))\n",
    "        # minList = np.reshape(minList, (-1, 1))\n",
    "        dfprice = priceList[:-5]\n",
    "        dfmin = minList[:-5]\n",
    "        predprice = priceList[-5:]\n",
    "        predmin = minList[-5:]\n",
    "        plt.plot(dfmin, dfprice)\n",
    "        plt.plot(predmin, predprice)\n",
    "        plt.show()\n",
    "\n",
    "    def getPredictions(self, currentKey):\n",
    "        path = currentKey + \".h5\"\n",
    "        model = models.load_model(path)\n",
    "\n",
    "        price = self.data['close'].values\n",
    "\n",
    "        # --------Predictions------------#\n",
    "        price = price.reshape(-1)\n",
    "        predictions = price[-self.time_steps:]\n",
    "        for derp in range(self.predictAhead):\n",
    "            x = predictions[-self.time_steps:]\n",
    "            x = x.reshape((1, self.time_steps, 1))\n",
    "            out = model.predict(x)[0][0]\n",
    "            predictions = np.append(predictions, out)\n",
    "        predictions = predictions[self.time_steps:]\n",
    "        # --------------------------------#\n",
    "        predictions = np.asarray(predictions)\n",
    "        self.pred = np.reshape(predictions, (-1, 1))\n",
    "        return(self.scaler.inverse_transform(self.pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        high      low     open  minute  relative_minute    close\n",
      "0    1.12410  1.12386  1.12410      24                0  1.12380\n",
      "1    1.12410  1.12380  1.12380      25                1  1.12410\n",
      "2    1.12416  1.12390  1.12410      26                2  1.12404\n",
      "3    1.12410  1.12380  1.12404      27                3  1.12405\n",
      "4    1.12417  1.12390  1.12405      28                4  1.12409\n",
      "..       ...      ...      ...     ...              ...      ...\n",
      "271  1.12420  1.12400  1.12420      55              271  1.12415\n",
      "272  1.12423  1.12400  1.12415      56              272  1.12419\n",
      "273  1.12430  1.12400  1.12419      57              273  1.12400\n",
      "274  1.12430  1.12400  1.12400      58              274  1.12421\n",
      "275  1.12430  1.12400  1.12421      59              275  1.12412\n",
      "\n",
      "[276 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "redis = Redis()\n",
    "handler = Handler(redis)\n",
    "scaler = MinMaxScaler()\n",
    "data = handler.load_all('USA')\n",
    "data = pd.DataFrame(data)\n",
    "print(data)\n",
    "data[['close']] = scaler.fit_transform(data[['close']])\n",
    "predictAhead = 5\n",
    "time_steps = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        high      low     open  minute  relative_minute     close\n",
      "0    1.12410  1.12386  1.12410      24                0  0.822511\n",
      "1    1.12410  1.12380  1.12380      25                1  0.952381\n",
      "2    1.12416  1.12390  1.12410      26                2  0.926407\n",
      "3    1.12410  1.12380  1.12404      27                3  0.930736\n",
      "4    1.12417  1.12390  1.12405      28                4  0.948052\n",
      "..       ...      ...      ...     ...              ...       ...\n",
      "271  1.12420  1.12400  1.12420      55              271  0.974026\n",
      "272  1.12423  1.12400  1.12415      56              272  0.991342\n",
      "273  1.12430  1.12400  1.12419      57              273  0.909091\n",
      "274  1.12430  1.12400  1.12400      58              274  1.000000\n",
      "275  1.12430  1.12400  1.12421      59              275  0.961039\n",
      "\n",
      "[276 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220 56\n"
     ]
    }
   ],
   "source": [
    "close = data['close'].values\n",
    "trainSize = 0.8\n",
    "\n",
    "####SPLIT#####\n",
    "\n",
    "trainSplit = int(len(data) * trainSize)\n",
    "train, test = close[:trainSplit], close[trainSplit:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.reshape(train, (-1,1))\n",
    "test = np.reshape(test, (-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series = TimeseriesGenerator(train, train, length=time_steps, batch_size=20)     \n",
    "test_series = TimeseriesGenerator(test, test, length=time_steps, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.3433\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.2713\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.2125\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.1524\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0949\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0466\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0140\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0085\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0087\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0074\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0074\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0073\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0072\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0070\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0070\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0071\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0067\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0068\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0066\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0066\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0065\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0064\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0063\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.0062\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x13d4b4550>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    LSTM(10,\n",
    "        activation='relu',\n",
    "        input_shape=(time_steps,1))\n",
    ")\n",
    "model.add()\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "num_epochs = 25\n",
    "model.fit_generator(train_series, epochs=num_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(test_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testVals = test[time_steps:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = scaler.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "testVals = scaler.inverse_transform(testVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.73395545e-08]\n"
     ]
    }
   ],
   "source": [
    "squared = []\n",
    "for p, t in zip(pred, testVals):\n",
    "    squared.append((t-p)**2)\n",
    "    mean = sum(squared)/len(squared)\n",
    "    \n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
